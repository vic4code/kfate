{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renset Classification on CIFAR 10\n",
    "\n",
    "In this example, we show you how to use torchvision model to make a federated classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: CIFAR 10\n",
    "\n",
    "You can download the CIFAR-10 dataset through this link: \n",
    "- https://webank-ai-1251170195.cos.ap-guangzhou.myqcloud.com/fate/examples/data/cifar-10.zip\n",
    "  \n",
    "The origin CIFAR-10 is from: \n",
    "- https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "  \n",
    "For the convinence of demonstrate, our clients will use same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/projects/fate/persistence/fate'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/data/projects/fate/persistence/fate/python/fate_client')\n",
    "sys.path.append('/data/projects/fate/persistence/fate/python')\n",
    "\n",
    "import os\n",
    "os.chdir(\"/data/projects/fate/persistence/fate\")\n",
    "os.environ['FATE_PROJECT_BASE'] = '/data/projects/fate/persistence/fate'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Test\n",
    "\n",
    "Firstly we locally test our model and dataset. If it works, we can submit a federated task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pipeline.component.nn import save_to_fate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%save_to_fate model resnet.py\n",
    "\n",
    "# model\n",
    "import torch as t\n",
    "from torch import nn\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "class Resnet(nn.Module):\n",
    "\n",
    "    def __init__(self, ):\n",
    "        super(Resnet, self).__init__()\n",
    "        self.resnet = resnet18()\n",
    "        self.classifier = t.nn.Linear(1000, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            return self.classifier(self.resnet(x))\n",
    "        else:\n",
    "            return self.softmax(self.classifier(self.resnet(x)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet(\n",
      "  (resnet): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1000, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Resnet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "from federatedml.nn.dataset.image import ImageDataset\n",
    "\n",
    "ds = ImageDataset()\n",
    "ds.load('/data/projects/fate/persistence/fate/examples/data/cifar10/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ipcl_python failed to import\n",
      "epoch is 0\n",
      "100%|██████████| 98/98 [00:35<00:00,  2.76it/s]\n",
      "epoch loss is 1.4889685620117188\n"
     ]
    }
   ],
   "source": [
    "# local test\n",
    "import torch as t\n",
    "from federatedml.nn.homo.trainer.fedavg_trainer import FedAVGTrainer\n",
    "\n",
    "trainer = FedAVGTrainer(epochs=1, batch_size=512, data_loader_worker=2)\n",
    "trainer.set_model(model)\n",
    "\n",
    "optimizer = t.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss = t.nn.CrossEntropyLoss()\n",
    "\n",
    "trainer.local_mode() # set local mode\n",
    "trainer.train(ds, None, optimizer, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit a federated task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': 'experiment', 'table_name': 'cifar10'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as t\n",
    "from torch import nn\n",
    "from pipeline import fate_torch_hook\n",
    "from pipeline.component import HomoNN\n",
    "from pipeline.backend.pipeline import PipeLine\n",
    "from pipeline.component import Reader, Evaluation, DataTransform\n",
    "from pipeline.interface import Data, Model\n",
    "\n",
    "fate_torch_hook(t)\n",
    "\n",
    "import os\n",
    "fate_project_path = os.path.abspath('/data/projects/fate')\n",
    "guest = 9999\n",
    "host = 10000\n",
    "pipeline = PipeLine().set_initiator(role='guest', party_id=guest).set_roles(guest=guest, host=host,\n",
    "                                                                            arbiter=host)\n",
    "data_0 = {\"name\": \"cifar10\", \"namespace\": \"experiment\"}\n",
    "data_path = fate_project_path + '/examples/data/cifar10/train'\n",
    "pipeline.bind_table(name=data_0['name'], namespace=data_0['namespace'], path=data_path)\n",
    "pipeline.bind_table(name=data_0['name'], namespace=data_0['namespace'], path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_0 = Reader(name=\"reader_0\")\n",
    "reader_0.get_party_instance(role='guest', party_id=guest).component_param(table=data_0)\n",
    "reader_0.get_party_instance(role='host', party_id=host).component_param(table=data_0)\n",
    "\n",
    "reader_1 = Reader(name=\"reader_1\")\n",
    "reader_1.get_party_instance(role='guest', party_id=guest).component_param(table=data_0)\n",
    "reader_1.get_party_instance(role='host', party_id=host).component_param(table=data_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.component.homo_nn import DatasetParam, TrainerParam\n",
    "\n",
    "model = t.nn.Sequential(\n",
    "    t.nn.CustModel(module_name='resnet', class_name='Resnet')\n",
    ")\n",
    "\n",
    "nn_component = HomoNN(name='nn_0',\n",
    "                      model=model, \n",
    "                      loss=t.nn.CrossEntropyLoss(),\n",
    "                      optimizer = t.optim.Adam(lr=0.001, weight_decay=0.001),\n",
    "                      dataset=DatasetParam(dataset_name='image'),  # 使用自定义的dataset\n",
    "                      trainer=TrainerParam(trainer_name='fedavg_trainer', epochs=1, batch_size=512, data_loader_worker=4),\n",
    "                      torch_seed=100\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pipeline.backend.pipeline.PipeLine at 0x7fadff1889d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.add_component(reader_0)\n",
    "pipeline.add_component(reader_1)\n",
    "pipeline.add_component(nn_component, data=Data(train_data=reader_0.output.data, validate_data=reader_1.output.data))\n",
    "pipeline.add_component(Evaluation(name='eval_0', eval_type='multi'), data=Data(data=nn_component.output.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pipeline.backend.pipeline.PipeLine at 0x7fadff1889d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-02-20 07:43:36.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mJob id is 202302200743362003410\n",
      "\u001b[0m\n",
      "\u001b[32m2023-02-20 07:43:36.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:00\u001b[0m\n",
      "\u001b[0mm2023-02-20 07:43:37.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2023-02-20 07:43:37.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:01\u001b[0m\n",
      "\u001b[32m2023-02-20 07:43:38.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:02\u001b[0m\n",
      "\u001b[32m2023-02-20 07:43:39.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:03\u001b[0m\n",
      "\u001b[32m2023-02-20 07:43:40.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:04\u001b[0m\n",
      "\u001b[32m2023-02-20 07:43:41.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:05\u001b[0m\n",
      "\u001b[32m2023-02-20 07:43:42.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:06\u001b[0m\n",
      "\u001b[0mm2023-02-20 07:43:43.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2023-02-20 07:43:43.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_1, time elapse: 0:00:07\u001b[0m\n",
      "\u001b[32m2023-02-20 07:43:44.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_1, time elapse: 0:00:08\u001b[0m\n",
      "\u001b[32m2023-02-20 07:43:45.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_1, time elapse: 0:00:09\u001b[0m\n",
      "\u001b[32m2023-02-20 07:43:46.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_1, time elapse: 0:00:10\u001b[0m\n",
      "\u001b[32m2023-02-20 07:43:47.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_1, time elapse: 0:00:11\u001b[0m\n",
      "\u001b[32m2023-02-20 07:43:48.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_1, time elapse: 0:00:12\u001b[0m\n",
      "\u001b[32m2023-02-20 07:43:49.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_1, time elapse: 0:00:13\u001b[0m\n",
      "\u001b[0mm2023-02-20 07:43:50.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2023-02-20 07:43:50.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:14\u001b[0m\n",
      "\u001b[32m2023-02-20 07:43:51.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:15\u001b[0m\n",
      "\u001b[32m2023-02-20 07:43:52.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:16\u001b[0m\n",
      "\u001b[32m2023-02-20 07:43:53.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:17\u001b[0m\n",
      "\u001b[32m2023-02-20 07:43:54.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:18\u001b[0m\n",
      "\u001b[32m2023-02-20 07:43:55.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:19\u001b[0m\n",
      "\u001b[32m2023-02-20 07:43:57.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:20\u001b[0m\n",
      "\u001b[32m2023-02-20 07:43:58.029\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:21\u001b[0m\n",
      "\u001b[32m2023-02-20 07:43:59.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:22\u001b[0m\n",
      "\u001b[32m2023-02-20 07:44:00.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component nn_0, time elapse: 0:00:23\u001b[0m\n",
      "\u001b[32m2023-02-20 07:44:02.100\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[31m\u001b[1mAn error has been caught in function '<module>', process 'MainProcess' (172), thread 'MainThread' (140388459525952):\u001b[0m\n",
      "\u001b[33m\u001b[1mTraceback (most recent call last):\u001b[0m\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "           │         │     └ {'__name__': '__main__', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nThis is separate from the ipykernel pack...\n",
      "           │         └ <code object <module> at 0x7faebc1ccdf0, file \"/usr/local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 1>\n",
      "           └ <function _run_code at 0x7faebc1dd940>\n",
      "  File \"/usr/local/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "         │     └ {'__name__': '__main__', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nThis is separate from the ipykernel pack...\n",
      "         └ <code object <module> at 0x7faebc1ccdf0, file \"/usr/local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 1>\n",
      "  File \"/usr/local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "    │   └ <bound method Application.launch_instance of <class 'ipykernel.kernelapp.IPKernelApp'>>\n",
      "    └ <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.8/site-packages/ipykernel/kernelapp.py'>\n",
      "  File \"/usr/local/lib/python3.8/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n",
      "    app.start()\n",
      "    │   └ <function IPKernelApp.start at 0x7faeb7d780d0>\n",
      "    └ <ipykernel.kernelapp.IPKernelApp object at 0x7faebc2eb700>\n",
      "  File \"/usr/local/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "    │    │       └ <function BaseAsyncIOLoop.start at 0x7faeb9a9e8b0>\n",
      "    │    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7faeb7d99520>\n",
      "    └ <ipykernel.kernelapp.IPKernelApp object at 0x7faebc2eb700>\n",
      "  File \"/usr/local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "    │    │            └ <function BaseEventLoop.run_forever at 0x7faebb9ceb80>\n",
      "    │    └ <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
      "    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7faeb7d99520>\n",
      "  File \"/usr/local/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "    │    └ <function BaseEventLoop._run_once at 0x7faebb9d0700>\n",
      "    └ <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
      "  File \"/usr/local/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "    │      └ <function Handle._run at 0x7faebba124c0>\n",
      "    └ <Handle <TaskWakeupMethWrapper object at 0x7fadc5480df0>(<Future finis...460>, ...],))>)>\n",
      "  File \"/usr/local/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "    │    │            │    │           │    └ <member '_args' of 'Handle' objects>\n",
      "    │    │            │    │           └ <Handle <TaskWakeupMethWrapper object at 0x7fadc5480df0>(<Future finis...460>, ...],))>)>\n",
      "    │    │            │    └ <member '_callback' of 'Handle' objects>\n",
      "    │    │            └ <Handle <TaskWakeupMethWrapper object at 0x7fadc5480df0>(<Future finis...460>, ...],))>)>\n",
      "    │    └ <member '_context' of 'Handle' objects>\n",
      "    └ <Handle <TaskWakeupMethWrapper object at 0x7fadc5480df0>(<Future finis...460>, ...],))>)>\n",
      "  File \"/usr/local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "          │    └ <function Kernel.process_one at 0x7faeb86dd160>\n",
      "          └ <ipykernel.ipkernel.IPythonKernel object at 0x7faeb7d35ee0>\n",
      "  File \"/usr/local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "          │         └ ([<zmq.sugar.frame.Frame object at 0x7faeb44f6b40>, <zmq.sugar.frame.Frame object at 0x7faeb44f6bf0>, <zmq.sugar.frame.Frame ...\n",
      "          └ <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object at 0x7faeb7d35ee0>>\n",
      "  File \"/usr/local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "          └ <coroutine object Kernel.execute_request at 0x7fae0e5c59c0>\n",
      "  File \"/usr/local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "                          └ <coroutine object IPythonKernel.do_execute at 0x7fae18b35e40>\n",
      "  File \"/usr/local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "          │     └ <function ZMQInteractiveShell.run_cell at 0x7faeb7d65820>\n",
      "          └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7faeb7d4a490>\n",
      "  File \"/usr/local/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 530, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "                             │       └ {'store_history': True, 'silent': False, 'cell_id': None}\n",
      "                             └ ('pipeline.fit() # submit pipeline here',)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n",
      "    result = self._run_cell(\n",
      "             │    └ <function InteractiveShell._run_cell at 0x7faeb916c700>\n",
      "             └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7faeb7d4a490>\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n",
      "    return runner(coro)\n",
      "           │      └ <coroutine object InteractiveShell.run_cell_async at 0x7faeb7d73ac0>\n",
      "           └ <function _pseudo_sync_runner at 0x7faeb9160040>\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "    │    └ <method 'send' of 'coroutine' objects>\n",
      "    └ <coroutine object InteractiveShell.run_cell_async at 0x7faeb7d73ac0>\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "                       │    │             │        │     └ '/tmp/ipykernel_172/4238494827.py'\n",
      "                       │    │             │        └ [<_ast.Expr object at 0x7fadff20db20>]\n",
      "                       │    │             └ <_ast.Module object at 0x7fadff20d610>\n",
      "                       │    └ <function InteractiveShell.run_ast_nodes at 0x7faeb916c9d0>\n",
      "                       └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7faeb7d4a490>\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "             │    │        │     │              └ False\n",
      "             │    │        │     └ <ExecutionResult object at 7fadff20d490, execution_count=33 error_before_exec=None error_in_exec=None info=<ExecutionInfo obj...\n",
      "             │    │        └ <code object <module> at 0x7fadff1a69d0, file \"/tmp/ipykernel_172/4238494827.py\", line 1>\n",
      "             │    └ <function InteractiveShell.run_code at 0x7faeb916ca60>\n",
      "             └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7faeb7d4a490>\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "         │         │    │               │    └ {'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, ...\n",
      "         │         │    │               └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7faeb7d4a490>\n",
      "         │         │    └ <property object at 0x7faeb915c810>\n",
      "         │         └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7faeb7d4a490>\n",
      "         └ <code object <module> at 0x7fadff1a69d0, file \"/tmp/ipykernel_172/4238494827.py\", line 1>\n",
      "\n",
      "> File \"\u001b[32m/tmp/ipykernel_172/\u001b[0m\u001b[32m\u001b[1m4238494827.py\u001b[0m\", line \u001b[33m1\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[1mpipeline\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mfit\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[30m\u001b[1m# submit pipeline here\u001b[0m\n",
      "    \u001b[36m│        └ \u001b[0m\u001b[36m\u001b[1m<function PipeLine.fit at 0x7fae0e5d3ee0>\u001b[0m\n",
      "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<pipeline.backend.pipeline.PipeLine object at 0x7fadff1889d0>\u001b[0m\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/site-packages/pipeline/backend/pipeline.py\", line 585, in fit\n",
      "    self._fit_status = self._job_invoker.monitor_job_status(self._train_job_id,\n",
      "    │    │             │    │            │                  │    └ '202302200743362003410'\n",
      "    │    │             │    │            │                  └ <pipeline.backend.pipeline.PipeLine object at 0x7fadff1889d0>\n",
      "    │    │             │    │            └ <function JobInvoker.monitor_job_status at 0x7fae0e5cd1f0>\n",
      "    │    │             │    └ <pipeline.utils.invoker.job_submitter.JobInvoker object at 0x7fadff188ac0>\n",
      "    │    │             └ <pipeline.backend.pipeline.PipeLine object at 0x7fadff1889d0>\n",
      "    │    └ None\n",
      "    └ <pipeline.backend.pipeline.PipeLine object at 0x7fadff1889d0>\n",
      "  File \"/usr/local/lib/python3.8/site-packages/pipeline/utils/invoker/job_submitter.py\", line 94, in monitor_job_status\n",
      "    raise ValueError(f\"Job is failed, please check out job {job_id} by fate board or fate_flow cli\")\n",
      "\n",
      "\u001b[31m\u001b[1mValueError\u001b[0m:\u001b[1m Job is failed, please check out job 202302200743362003410 by fate board or fate_flow cli\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Job is failed, please check out job 202302200743362003410 by fate board or fate_flow cli",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# submit pipeline here\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/loguru/_logger.py:1226\u001b[0m, in \u001b[0;36mLogger.catch.<locals>.Catcher.__call__.<locals>.catch_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcatch_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1225\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m catcher:\n\u001b[0;32m-> 1226\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pipeline/backend/pipeline.py:585\u001b[0m, in \u001b[0;36mPipeLine.fit\u001b[0;34m(self, job_parameters, callback_func)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_board_url \u001b[38;5;241m=\u001b[39m detail_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboard_url\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_info \u001b[38;5;241m=\u001b[39m SimpleNamespace(model_id\u001b[38;5;241m=\u001b[39mdetail_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_info\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_id\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    583\u001b[0m                                    model_version\u001b[38;5;241m=\u001b[39mdetail_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_info\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_version\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 585\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_job_invoker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmonitor_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_job_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initiator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrole\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initiator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparty_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pipeline/utils/invoker/job_submitter.py:94\u001b[0m, in \u001b[0;36mJobInvoker.monitor_job_status\u001b[0;34m(self, job_id, role, party_id, previous_status)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StatusCode\u001b[38;5;241m.\u001b[39mSUCCESS\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m JobStatus\u001b[38;5;241m.\u001b[39mFAILED:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob is failed, please check out job \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by fate board or fate_flow cli\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m JobStatus\u001b[38;5;241m.\u001b[39mWAITING:\n\u001b[1;32m     97\u001b[0m     elapse_seconds \u001b[38;5;241m=\u001b[39m timedelta(seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time))\n",
      "\u001b[0;31mValueError\u001b[0m: Job is failed, please check out job 202302200743362003410 by fate board or fate_flow cli"
     ]
    }
   ],
   "source": [
    "pipeline.fit() # submit pipeline here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "d29574a2ab71ec988cdcd4d29c58400bd2037cad632b9528d973466f7fb6f853"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
